{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4690b861-542a-4196-b3f0-41cd68aa86be",
   "metadata": {},
   "source": [
    "# Lattice Latent Variable Model (Lattice-LVM) Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16edbafa-3f49-49c5-bad4-4252c286c4d2",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b66182-f8c7-4c4d-81cf-e6ac9eec679a",
   "metadata": {},
   "source": [
    "The functions below load gerbil data and create a dataloader for use in the model. I know gerbils are not birds, but I named the functions/file before I knew we'd be running this on gerbils and it just happens to work for gerbils too."
   ]
  },
  {
   "cell_type": "code",
   "id": "5bdbe609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:24:37.431597Z",
     "start_time": "2025-09-19T15:24:37.427217Z"
    }
   },
   "source": [
    "exp = 112"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7934d26a-e07f-465a-b66f-a451f17683e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:24:41.671552Z",
     "start_time": "2025-09-19T15:24:41.560322Z"
    }
   },
   "source": "!uv pip install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2mUsing Python 3.11.12 environment at: C:\\Users\\gg3065\\code\\vocalizations\\.venv\u001B[0m\n",
      "\u001B[2mAudited \u001B[1m2 packages\u001B[0m \u001B[2min 9ms\u001B[0m\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9c09b20b-430b-4b8e-8f28-064af0691b64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:27:18.761244Z",
     "start_time": "2025-09-19T15:26:25.274805Z"
    }
   },
   "source": [
    "from data.bird_data import load_gerbils,bird_data\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Becasue I'm using Windows, can't use Miles's lambdas\n",
    "def spec_to_tensor(x: np.ndarray) -> torch.Tensor:\n",
    "    # x shape: H x W numpy array\n",
    "    return torch.from_numpy(x).to(torch.float32).unsqueeze(0)\n",
    "\n",
    "data_path = fr\"\\\\sanesstorage.cns.nyu.edu\\archive\\ginosar\\Processed_data\\Audio\\{exp}\" #'/mnt/home/mmartinez/ceph/data/gerbil/gily' # this directory contains .hdf5 files with spectrograms from your audio\n",
    "n_workers = max(os.cpu_count()-1,1) #len(os.sched_getaffinity(0))\n",
    "print(n_workers)\n",
    "\n",
    "(train_fns,test_fns),(train_ids,test_ids),specs_per_file = load_gerbils(data_path,specs_per_file=100,families=[1],test_size=0.2,seed=92,check=True)\n",
    "### specs_per_file is how many spectrograms are in each .hdf5 file, families is the family number we're trying to load (I just set the data you sent to family 1),\n",
    "### test_size is the portion of the data that will remain unseen in training, seed is used to maintain reproducibility, check determines whether we check to see if \n",
    "### all files have 100 vocalization each\n",
    "\n",
    "train_dataset = bird_data(train_fns, train_ids,specs_per_file=specs_per_file,transform=spec_to_tensor,conditional=False)\n",
    "# *GILY*: this is Mile's version, but I can't use lambda on multiprocessing in Windows\n",
    "# train_dataset = bird_data(train_fns,train_ids,specs_per_file=specs_per_file,transform=lambda x: torch.from_numpy(x).to(torch.float32).unsqueeze(0), conditional=False)\n",
    "\n",
    "### Unfortunately, transform has to be a little weird because of how I saved the spectrograms. This performs these operations on each spectrogram before returning them\n",
    "### Conditional determines if we want to condition our model on other variables (fm, entropy, syllable length, etc)\n",
    "\n",
    "test_dataset = bird_data(test_fns, test_ids,specs_per_file=specs_per_file,transform=spec_to_tensor, conditional=False)\n",
    "# *GILY*: this is Mile's version, but I can't use lambda on multiprocessing in Windows\n",
    "# test_dataset = bird_data(test_fns,test_ids,specs_per_file=specs_per_file,transform=lambda x: torch.from_numpy(x).to(torch.float32).unsqueeze(0), conditional=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=64,num_workers=n_workers,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=64,num_workers=n_workers,shuffle=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "loading family1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2081/2081 [00:51<00:00, 40.22it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "770a8bf8-a573-4c8d-9510-036dc2ed1d98",
   "metadata": {},
   "source": [
    "## Defining a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d5af3-9625-4f33-9c06-bcf90b3974fd",
   "metadata": {},
   "source": [
    "Now we can set up our model for training. This is done by selecting a grid over our latent space and a model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "id": "3aaec5bf-79fa-4bb1-8e1b-a6654d355655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:27:34.126217Z",
     "start_time": "2025-09-19T15:27:34.100323Z"
    }
   },
   "source": [
    "from models.sampling import gen_fib_basis,gen_korobov_basis\n",
    "from models.utils import get_decoder_arch\n",
    "from models.qmc_base import QMCLVM\n",
    "import torch\n",
    "\n",
    "latent_dim=2 # sets our latent dimension\n",
    "### If we use two dimensions, we should use gen_fib_basis for our grid over the latent space\n",
    "### If more than two dimensions, we should use gen_korobov_basis. This requires additional arguments, \n",
    "### if you want to use this see help(gen_korobov_basis) for good argument values\n",
    "\n",
    "latent_grid = gen_fib_basis(m=15) # m determines both the size of our grid and spacing of points\n",
    "## if you want to plot this, you will need to plot (latent_grid % 1) instead of latent_grid\n",
    "\n",
    "\n",
    "dataset = 'gerbil_ava' # used for getting a pre-selected decoder architecture\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') # use gpu if possible\n",
    "\n",
    "decoder = get_decoder_arch(dataset_name=dataset,latent_dim=latent_dim) # get_decoder_arch has a set of fixed architectures -- \n",
    "### if you want to play around with your own, you can make one using nn.Sequential (strings together layers). That's all that the \n",
    "### decoders are -- nn.Sequential instances"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "74646a94-7f41-4530-aa6b-780df80a26cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:25:17.488687Z",
     "start_time": "2025-09-19T15:25:16.275353Z"
    }
   },
   "source": [
    "from train.losses import binary_evidence,binary_lp,gaussian_evidence,gaussian_lp\n",
    "model = QMCLVM(latent_dim=latent_dim,device=device,decoder=decoder)\n",
    "\n",
    "## binary evidence\n",
    "qmc_loss_func = binary_evidence # I used this for training models, but we can also use gaussian (what the VAE uses)\n",
    "qmc_lp = binary_lp\n",
    "\n",
    "## gaussian evidence\n",
    "# qmc_loss_func = lambda samples,data: gaussian_evidence(samples,data,var=0.01) # var is the inverse of precision from the VAE\n",
    "# qmc_lp = lambda samples,data: gaussian_lp(samples,data,var=0.01)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "2e52c575-7d0a-42a7-b941-52b4307017e7",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "a55dc942-5626-4fb2-b11b-1f9d98449d9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:27:22.906071Z",
     "start_time": "2025-09-19T15:27:18.761244Z"
    }
   },
   "source": [
    "from train.train import train_loop\n",
    "nEpochs=10\n",
    "#### to speed up training, you can decrease grid size (decrease m) at the expense of model performance,\n",
    "#### or increase batch size  \n",
    "model,opt,losses = train_loop(model,train_loader,latent_grid.to(device),qmc_loss_func,\\\n",
    "                                                                    nEpochs=nEpochs,verbose=False,\n",
    "                                                                    conditional=False)\n",
    "        "
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m nEpochs=\u001B[32m10\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m#### to speed up training, you can decrease grid size (decrease m) at the expense of model performance,\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m#### or increase batch size  \u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m model,opt,losses = \u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlatent_grid\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mqmc_loss_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m\\\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m                                                                    \u001B[49m\u001B[43mnEpochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnEpochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m                                                                    \u001B[49m\u001B[43mconditional\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\qmc_deep_gen\\train\\train.py:123\u001B[39m, in \u001B[36mtrain_loop\u001B[39m\u001B[34m(model, loader, base_sequence, loss_function, nEpochs, verbose, random, mod, conditional, out_dir, run_id, checkpoint_every)\u001B[39m\n\u001B[32m    119\u001B[39m     batch_loss, model, optimizer = train_epoch_verbose(\n\u001B[32m    120\u001B[39m         model, optimizer, loader, base_sequence, loss_function,\n\u001B[32m    121\u001B[39m         random=random, mod=mod, conditional=conditional)\n\u001B[32m    122\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m123\u001B[39m     batch_loss, model, optimizer = \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    124\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbase_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    125\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrandom\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrandom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmod\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconditional\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconditional\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    127\u001B[39m losses += batch_loss\n\u001B[32m    129\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\qmc_deep_gen\\train\\train.py:13\u001B[39m, in \u001B[36mtrain_epoch\u001B[39m\u001B[34m(model, optimizer, loader, base_sequence, loss_function, random, mod, conditional)\u001B[39m\n\u001B[32m     11\u001B[39m train_loss = \u001B[32m0\u001B[39m\n\u001B[32m     12\u001B[39m epoch_losses = []\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx,batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m     14\u001B[39m     data= batch[\u001B[32m0\u001B[39m]\n\u001B[32m     15\u001B[39m     data = data.to(model.device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:491\u001B[39m, in \u001B[36mDataLoader.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    489\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._iterator\n\u001B[32m    490\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m491\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:422\u001B[39m, in \u001B[36mDataLoader._get_iterator\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    420\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    421\u001B[39m     \u001B[38;5;28mself\u001B[39m.check_worker_number_rationality()\n\u001B[32m--> \u001B[39m\u001B[32m422\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001B[39m, in \u001B[36m_MultiProcessingDataLoaderIter.__init__\u001B[39m\u001B[34m(self, loader)\u001B[39m\n\u001B[32m   1139\u001B[39m w.daemon = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m   1140\u001B[39m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[32m   1141\u001B[39m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[32m   1142\u001B[39m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[32m   1143\u001B[39m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[32m   1144\u001B[39m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[32m   1145\u001B[39m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1146\u001B[39m \u001B[43mw\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1147\u001B[39m \u001B[38;5;28mself\u001B[39m._index_queues.append(index_queue)\n\u001B[32m   1148\u001B[39m \u001B[38;5;28mself\u001B[39m._workers.append(w)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\multiprocessing\\process.py:121\u001B[39m, in \u001B[36mBaseProcess.start\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process._config.get(\u001B[33m'\u001B[39m\u001B[33mdaemon\u001B[39m\u001B[33m'\u001B[39m), \\\n\u001B[32m    119\u001B[39m        \u001B[33m'\u001B[39m\u001B[33mdaemonic processes are not allowed to have children\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    120\u001B[39m _cleanup()\n\u001B[32m--> \u001B[39m\u001B[32m121\u001B[39m \u001B[38;5;28mself\u001B[39m._popen = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[38;5;28mself\u001B[39m._sentinel = \u001B[38;5;28mself\u001B[39m._popen.sentinel\n\u001B[32m    123\u001B[39m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[32m    124\u001B[39m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\multiprocessing\\context.py:224\u001B[39m, in \u001B[36mProcess._Popen\u001B[39m\u001B[34m(process_obj)\u001B[39m\n\u001B[32m    222\u001B[39m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[32m    223\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_Popen\u001B[39m(process_obj):\n\u001B[32m--> \u001B[39m\u001B[32m224\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mProcess\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\multiprocessing\\context.py:336\u001B[39m, in \u001B[36mSpawnProcess._Popen\u001B[39m\u001B[34m(process_obj)\u001B[39m\n\u001B[32m    333\u001B[39m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[32m    334\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_Popen\u001B[39m(process_obj):\n\u001B[32m    335\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpopen_spawn_win32\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[32m--> \u001B[39m\u001B[32m336\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001B[39m, in \u001B[36mPopen.__init__\u001B[39m\u001B[34m(self, process_obj)\u001B[39m\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     94\u001B[39m     reduction.dump(prep_data, to_child)\n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m     \u001B[43mreduction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     96\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m     97\u001B[39m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\multiprocessing\\reduction.py:60\u001B[39m, in \u001B[36mdump\u001B[39m\u001B[34m(obj, file, protocol)\u001B[39m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdump\u001B[39m(obj, file, protocol=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m     59\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "c9649e10-14f1-4d2a-9f92-e60212e1e534",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:41:37.584990Z",
     "start_time": "2025-09-19T15:41:27.343174Z"
    }
   },
   "source": [
    "from train.train import test_epoch\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_losses =  test_epoch(model,test_loader,latent_grid.to(device),qmc_loss_func,conditional=False)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/652 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 34660, 49844, 44176, 45944, 56260, 21356) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mEmpty\u001B[39m                                     Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1251\u001B[39m, in \u001B[36m_MultiProcessingDataLoaderIter._try_get_data\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m   1250\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1251\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_data_queue\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1252\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\multiprocessing\\queues.py:114\u001B[39m, in \u001B[36mQueue.get\u001B[39m\u001B[34m(self, block, timeout)\u001B[39m\n\u001B[32m    113\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._poll(timeout):\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[32m    115\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._poll():\n",
      "\u001B[31mEmpty\u001B[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m model.eval()\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     test_losses =  \u001B[43mtest_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlatent_grid\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mqmc_loss_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43mconditional\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\qmc_deep_gen\\train\\train.py:59\u001B[39m, in \u001B[36mtest_epoch\u001B[39m\u001B[34m(model, loader, base_sequence, loss_function, conditional)\u001B[39m\n\u001B[32m     57\u001B[39m epoch_losses = []\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m     61\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\.venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[39m, in \u001B[36mtqdm.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1178\u001B[39m time = \u001B[38;5;28mself\u001B[39m._time\n\u001B[32m   1180\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1181\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[32m   1184\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    705\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    706\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    707\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m708\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    709\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    710\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    711\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    712\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    713\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    714\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1458\u001B[39m, in \u001B[36m_MultiProcessingDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1455\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._process_data(data)\n\u001B[32m   1457\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._tasks_outstanding > \u001B[32m0\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1458\u001B[39m idx, data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1459\u001B[39m \u001B[38;5;28mself\u001B[39m._tasks_outstanding -= \u001B[32m1\u001B[39m\n\u001B[32m   1460\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable:\n\u001B[32m   1461\u001B[39m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1420\u001B[39m, in \u001B[36m_MultiProcessingDataLoaderIter._get_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1416\u001B[39m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[32m   1417\u001B[39m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[32m   1418\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1419\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1420\u001B[39m         success, data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1421\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[32m   1422\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\code\\vocalizations\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1264\u001B[39m, in \u001B[36m_MultiProcessingDataLoaderIter._try_get_data\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m   1262\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_workers) > \u001B[32m0\u001B[39m:\n\u001B[32m   1263\u001B[39m     pids_str = \u001B[33m\"\u001B[39m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m.join(\u001B[38;5;28mstr\u001B[39m(w.pid) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m failed_workers)\n\u001B[32m-> \u001B[39m\u001B[32m1264\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   1265\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mDataLoader worker (pid(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpids_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m) exited unexpectedly\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1266\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m   1267\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, queue.Empty):\n\u001B[32m   1268\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[31mRuntimeError\u001B[39m: DataLoader worker (pid(s) 34660, 49844, 44176, 45944, 56260, 21356) exited unexpectedly"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "284d0624-5076-4608-ac09-c1c38592c601",
   "metadata": {},
   "source": [
    "## Basic visualization"
   ]
  },
  {
   "cell_type": "code",
   "id": "a4ac42e6-ae3e-4ad9-856c-c85e2817ee1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:41:47.953959Z",
     "start_time": "2025-09-19T15:41:47.544648Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plotting.visualize import format_plot_axis\n",
    "def qmc_train_plot(qmc_train_losses,qmc_test_losses,save_fn='',show=False):\n",
    "\n",
    "    qmc_train_losses,qmc_test_losses = np.array(qmc_train_losses),np.array(qmc_test_losses)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    N = len(qmc_train_losses)\n",
    "\n",
    "    ax.plot(-qmc_train_losses,label = 'Model evidence',color='tab:blue')\n",
    "    xax = list(ax.get_xticks()) \n",
    "    if xax[-1] >= N + N//5:\n",
    "        xax = xax[:-1]\n",
    "    xticklabels = xax + ['Test']\n",
    "    xax += [N + N//5] \n",
    "    ax.errorbar(N + N//5,np.nanmean(-qmc_test_losses),yerr =np.nanstd(-qmc_test_losses),capsize=6,linestyle='',color='tab:blue')\n",
    "    ax =  format_plot_axis(ax,ylabel='Model evidence',xlabel='update number',xticks=xax,xticklabels=xticklabels)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_fn)\n",
    "\n",
    "    plt.close()"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "11bede43-8f0d-48dc-81d4-85e234fa40c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:41:50.706614Z",
     "start_time": "2025-09-19T15:41:50.655168Z"
    }
   },
   "source": [
    "from plotting.visualize import model_grid_plot,qmc_train_plot\n",
    "qmc_train_plot(losses,test_losses,show=True)\n",
    "model_grid_plot(model,n_samples_dim=10,origin='lower',cm='inferno') # increase n_samples_dim for a denser plot that takes longer to show"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplotting\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mvisualize\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m model_grid_plot,qmc_train_plot\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m qmc_train_plot(\u001B[43mlosses\u001B[49m,test_losses,show=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m      3\u001B[39m model_grid_plot(model,n_samples_dim=\u001B[32m10\u001B[39m,origin=\u001B[33m'\u001B[39m\u001B[33mlower\u001B[39m\u001B[33m'\u001B[39m,cm=\u001B[33m'\u001B[39m\u001B[33minferno\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;66;03m# increase n_samples_dim for a denser plot that takes longer to show\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'losses' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "af737404-1968-4177-97b1-4d9dcac2aae6",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b498f1-abff-4560-89c2-6c22066e238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings,test_labels = model.embed_data(latent_grid.to(device),test_loader,qmc_lp, embed_type='rqmc',n_samples=5)\n",
    "## different embedding types are:\n",
    "## argmax (maximum likelihood grid point for each sample in latent space)\n",
    "## posterior (sum over grid points, weighted by likelihood)\n",
    "## rqmc (average weighted sum over randomly shifted grid points, averaged over n_samples grid shifts)\n",
    "\n",
    "### unfortunately, at this point test_labels are just family ID (so all 1, for this dataset) -- I haven't implemented an easy way to \n",
    "### label by location, file number, etc. yet. Will be doing that soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a387f0-bec2-4849-8201-188f4b8e5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from plotting.visualize import format_plot_axis\n",
    "ax = plt.gca()\n",
    "ax.scatter(test_embeddings[:,0],test_embeddings[:,1],s=1,alpha=0.5)\n",
    "ax = format_plot_axis(ax,xlim=(0,1),ylim=(0,1),xlabel='Latent dim 1',ylabel='Latent dim 2',title='Latent embeddings of test dataset')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vocalizations)",
   "language": "python",
   "name": "vocalizations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
